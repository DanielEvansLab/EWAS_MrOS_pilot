---
title: "EWAS pilot in MrOS"
author: "Dan Evans"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  BiocStyle::html_document:
    toc_float: true
    toc_depth: 3
    fig_caption: yes

fontsize: 14 pt

vignette: >
  %\VignetteIndexEntry{EWAS pilot in MrOS}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}

---

# Introduction

EPIC array has type 1 and type 2 probes. Type 1 probes are from the old 27K array that uses 2 bead types per CpG. The type I probes are labeled I-green and I-red. The newer type 2 probes uses one bead type. Most of the EPIC array probes are type 2. 

DNA methylation quantity is expressed as $\beta$ 

$$ \beta = M/(M + U)  $$

Where M = hybridization signal from a methylated version of a cytosine nucleotide and 
U =  hybridization signal from an unmethylated version of a cytosine nucleotide. 

Beta can be interpreted as the proportion of methylation signal for a probe, and values range from 0 to 1. Beta is easy to interpret for humans, but typically has a bimodal distribution that is suboptimal for statistical modeling. Thus, we analyze M-values, which are another way to express methylation values for probes. 

$$ M-value = log_2(M/U) $$

A detection probability represents the probability of a detected signal being background flourescence. If the probability is high, the signal is more likely to be background, and the value should be set to missing.

Standard workflows suggest to remove data points with detection P-value > 0.05.  

# Processing Illumina EPIC array with Sesame package

## Sesame introduction

- EWAS array Illumina EPIC 850 + custom content

- LifeEGX worked with Sesame developer to process chips. LifeEGX recommends Sesame

- Sesame is a [bioconductor package](https://www.bioconductor.org/packages/release/bioc/html/sesame.html)
  + Improvements on previous EWAS packages for low-level processing. 
  + Existing methods do not identify artifacts associated with detection failure. Sources of failure include: insufficient DNA due to germline or somatic deletions or hyperpolymorphism, probe cross-hybridization. 
  + P-value with out-of-band array hybridization: pOOBAH
  + Reduces technical artifacts

```{r, setup}
knitr::opts_chunk$set(cache.lazy = FALSE)
```

## Sesame installation on UCR cluster

Installation of sesame and dependencies went fine, no errors or warnings.

Upgrade installed sesame version 1.6.

Can check version of loaded packages with sessionInfo()

```{r, eval = FALSE}
BiocManager::install("sesame", lib = "~/Rlibs")
BiocManager::install("sesameData", lib = "~/Rlibs")
#BiocManager::install('zwdzwd/sesameData', lib = "~/Rlibs")
```

## Load libraries
```{r message = FALSE}
library(tidyverse)
library(readxl)
library(knitr)
library(sesame)
library(wheatmap)
library(multtest)
library(limma)
library(sva)
library(RColorBrewer)
library(EnhancedVolcano)
library(kableExtra)
```

## Import and normalize data

Reading the data with openSesame takes about 55 minutes. 

Create ExpressionSet object saved to disk for easy subsequent loading.

```{r message = FALSE, warning = FALSE, cache = TRUE}

# manifest <- read.csv("../data/raw/Evans_Project_002/CombinedManifestEPICplus.manifest.LifeEGX.csv", header = T, stringsAsFactors = F, na.strings = c("NA", ""))

manifest <- readRDS("../data/raw/Evans_Project_002/OpenDMAP_sesame_manifest.rds")

IDATprefixes <- searchIDATprefixes(dir.name = "../data/raw/Evans_Project_002/idat_Files")

#specifying custom manifest works using rds manifest, not the csv manifest
t1 <- Sys.time()
betas <- openSesame(IDATprefixes, 'custom', manifest = manifest)
Sys.time() - t1
#Warnings issued. The sesame vignette also displayed these warnings, so I'm not concerned. 
#50: In readChar(con, nchars = n) : truncating string with embedded nuls

sum(is.na(betas))
sum(is.na(betas))/length(betas)
sum(betas <= 0 & !is.na(betas))
sum(betas >= 1 & !is.na(betas))

Mvals <- BetaValueToMValue(betas)

#create sample annotation file for eset
dat_pData <- read_csv("../data/raw/Evans_Project_002/Evans_Project_002_Sample_Sheet.csv", skip = 8)
dat_pData <- dat_pData %>%
	mutate(Basename = paste(Sentrix_ID, Sentrix_Position, sep = "_"))

#read in dup list
dupList <- read_excel("../data/raw/MrOS_duplicates.xlsx")
names(dupList)[1] <- "dupMrOSID"

#sample IDs in sample sheet are in the same order as sample names in betas file
sum(colnames(betas) != dat_pData$Basename)
sum(colnames(betas) == dat_pData$Basename)
cbind(colnames(betas), dat_pData$Basename)
#merge dups into sample sheet
dat_pData <- dat_pData %>%
	mutate(sampOrder = seq_along(Sample_Name)) %>%
	left_join(dupList, by = c("Sample_Name" = "dup_ID")) %>%
	arrange(sampOrder)

colnames(Mvals) <- dat_pData$Sample_Name
row.names(dat_pData) <- dat_pData$Sample_Name

# Feature annotation
# Create feature annotation file. Find which probes are in 450K annotation that are not in EPIC, then combine_rows. Ensure all probes in the data are included in the annotation, and in the same order, then can create eset. 
annot_450 <- read_tsv("~/bigdata/EWAStools/arrayAnnotation/HM450.hg19.manifest.tsv")
xreact_450 <- read_xlsx("~/bigdata/EWAStools/arrayAnnotation/48639-non-specific-probes-Illumina450k.xlsx", sheet = "nonspecific cg probes")
# Are all cross-reactive probes marked as masked in annot_450? If so, I don't need to readin the cross-reactive list in the future
sum(!is.na(xreact_450$TargetID))
length(xreact_450$TargetID) #29,233
sum(!is.na(annot_450$probeID))
length(annot_450$probeID) #485,577
sum(xreact_450$TargetID %in% annot_450$probeID) #29,233
#Yes, all cross-reactive probes are in the 450K annotation file. 
# All they all marked as MASKED?
table(annot_450$MASK_general[annot_450$probeID %in% xreact_450$TargetID])
table(annot_450$MASK_mapping[annot_450$probeID %in% xreact_450$TargetID])
table(list(mask_general =  annot_450$MASK_general[annot_450$probeID %in% xreact_450$TargetID],
      mask_mapping = annot_450$MASK_mapping[annot_450$probeID %in% xreact_450$TargetID]
      ),
      deparse.level = 2
      )
#There are 2097 cross-reactive probes that are not labeled by either of the MASK variables
#Conclusion, I need to exclude cross-reactive probes from 450K array probes
#Just set them to TRUE for MASK_general
annot_450$MASK_general[annot_450$probeID %in% xreact_450$TargetID] <- TRUE
table(annot_450$MASK_general[annot_450$probeID %in% xreact_450$TargetID])
#EPIC Annotation
# Set MASK_general to TRUE for cross-reactive probes in EPIC array
annot_EPIC <- read_tsv("~/bigdata/EWAStools/arrayAnnotation/EPIC.hg19.manifest.tsv")
length(annot_EPIC$probeID)
table(annot_EPIC$MASK_general[annot_EPIC$probeID %in% xreact_450$TargetID])
annot_EPIC$MASK_general[annot_EPIC$probeID %in% xreact_450$TargetID] <- TRUE
#Remove EPIC probes that are on 450K
sum(annot_450$probeID %in% annot_EPIC$probeID)
sum(!annot_450$probeID %in% annot_EPIC$probeID)
annot_450 <- annot_450[!annot_450$probeID %in% annot_EPIC$probeID,]

#Combine 450 and EPIC
dat_fData <- bind_rows("EPIC" = annot_EPIC, "HM450" = annot_450, .id = "array")
#898,983 rows 
#Subset dat_fData to probes in data, then make same order
Mvals_probes <- str_split(string = rownames(Mvals), pattern = "_")
Mvals_probes <- map_chr(Mvals_probes, function(x) x[1])
length(Mvals_probes)
dim(Mvals)
#868,701 probes from Mvals data
sum(duplicated(Mvals_probes))
#There are 210 duplicate probes when deleting everything after "_"! For those dups, I'll simply include the original probe ID.
rownames(Mvals)[duplicated(Mvals_probes)]
Mvals_probes[duplicated(Mvals_probes)] <- rownames(Mvals)[duplicated(Mvals_probes)]
Mvals_annot <- data.frame(probeID = Mvals_probes, onChip = 1L, stringsAsFactors = FALSE)
dat_fData <- Mvals_annot %>%
	left_join(dat_fData, by = "probeID")
#868,701 in merged result
sum(is.na(dat_fData$probeID)) #0 
sum(is.na(dat_fData$onChip)) #0
sum(is.na(dat_fData$array)) #210, same as duplicated probes
sum(is.na(dat_fData$MASK_general)) #210, same as duplicated probes
table(dat_fData$array)
#Match probe order
dat_fData <- dat_fData[match(Mvals_probes, dat_fData$probeID),]
sum(Mvals_probes != dat_fData$probeID)
row.names(dat_fData) <- dat_fData$probeID
rownames(Mvals) <- dat_fData$probeID

#Create eset
eset_Mvals <- ExpressionSet(assayData = Mvals,
			    phenoData = AnnotatedDataFrame(dat_pData),
			    featureData = AnnotatedDataFrame(dat_fData)
			    )

write_rds(eset_Mvals, path = "../data/formatted/eset_Mvals.rds")

```

## Sesame standard QC


```{r message = FALSE, warning = FALSE, cache = TRUE, results = "asis"}
pdat <- pData(eset_Mvals)
IDATprefixes <- searchIDATprefixes(dir.name = "../data/raw/Evans_Project_002/idat_Files")
ssets <- lapply(IDATprefixes, readIDATpair)
qc10 <- do.call(rbind, lapply(ssets, function(x) as.data.frame(sesameQC(x))))
qc10 <- qc10 %>%
	mutate(sample_name = pdat$Sample_Name) %>%
	select(sample_name, everything())
qcvars <- c("sample_name", "num_probes_cg", "num_na_cg", "frac_na_cg", "mean_intensity", "mean_beta_cg", "frac_meth_cg", "frac_unmeth_cg", "sex", "age", "ethnicity", "GCT")
qc10 %>%
	select(any_of(qcvars)) %>%
	kable

#annoS <- sesameDataPullVariantAnno_SNP('EPIC','hg19')

```

## Mean intensity

The mean {M,U} intensity can be reached by mean_intensity. Similarly, the mean M+U intensity can be reached by mean_intensity_total. Low intensities are symptomatic of low input or poor hybridization.

```{r results = "asis"}

p1 <- ggplot(qc10) +
    geom_bar(aes(sample_name, mean_intensity), stat='identity') +
    xlab('Sample Name') + ylab('Mean Intensity') +
    ylim(0,18000) +
    theme(axis.text.x = element_text(angle=90, vjust=0.5, hjust=1))
p2 <- ggplot(qc10) +
    geom_bar(aes(sample_name, mean_intensity_total), stat='identity') +
    xlab('Sample Name') + ylab('Mean M+U Intensity') +
    ylim(0,18000) +
    theme(axis.text.x = element_text(angle=90, vjust=0.5, hjust=1))
WGG(p1) + WGG(p2, RightOf())

```

## Missing analysis 

The fraction of NAs is a sign of masking due to a variety of reasons, including failed detection, high background, putative low quality probes, etc.

Now we move back to the normalized Mvals to identify and remove failed samples and probes. I'll also remove probes that are recommended to be masked from the annotation file. 
First, remove masked probes. Then, remove failed samples and failed probes. How many samples are missing across all probes? How many probes are missing across all samples? 

```{r results = "asis", cache = TRUE}
eset_Mvals <- read_rds("../data/formatted/eset_Mvals.rds")
dim(eset_Mvals)
#Remove 210 probes without annotation
f_dat <- fData(eset_Mvals)
sum(is.na(f_dat$MASK_general))
eset_Mvals <- eset_Mvals[!is.na(f_dat$MASK_general),]
#Remove flagged probes. Keep non-flagged, which are FALSE.
f_dat <- fData(eset_Mvals)
table(f_dat$MASK_general)
eset_Mvals <- eset_Mvals[!f_dat$MASK_general,]
dim(eset_Mvals)

e <- exprs(eset_Mvals)
pdat <- pData(eset_Mvals)

miss_sample <- apply(e, 2, function(x) sum(is.na(x))/length(x) )
miss_probe <- apply(e, 1, function(x) sum(is.na(x))/length(x) )
length(miss_sample)
length(miss_probe)
sum(is.na(miss_sample))
sum(is.na(miss_probe))
sum(miss_sample >= 0.95) #0 samples have missing rate greater than 95% 
#no samples that are essentially blanks.
sum(miss_probe >= 1) #Completely missing probes.
#Remove these probes, then determine number of samples with missing rate>0.05.
sum(miss_probe >= 0.95) 

#Remove failed probes
# Keep probes with < 0.95 missingness
eset_Mvals <- eset_Mvals[miss_probe < 0.95 ,]
dim(eset_Mvals)

#Reestimate probe and sample missing rates after removing failed probes
e <- exprs(eset_Mvals)
pdat <- pData(eset_Mvals)
miss_sample <- apply(e, 2, function(x) sum(is.na(x))/length(x) )
miss_probe <- apply(e, 1, function(x) sum(is.na(x))/length(x) )
sum(miss_probe > 0.05) #62532 probes with missing rate greater than 5%
sum(miss_probe > 0.05)/length(miss_probe) #8% probes removed 
sum(miss_sample > 0.10) # 7 samples with > 10% missing 
sort(miss_sample[miss_sample > 0.1], decreasing = TRUE)
sum(miss_sample > 0.10)/length(miss_sample) #4% samples removed

#Sample missing rate
data.frame(sampleID = names(miss_sample), missing_percent = miss_sample, stringsAsFactors = F) %>%
	arrange(desc(missing_percent)) %>%
	slice_head(prop = 0.25) %>%
	kable

#After removing failed probes, display probe missing rate
#Number of probes with no missings
sum(miss_probe == 0)
#Number of probes with at least one missing
sum(miss_probe > 0)
#Number of probes with > 5% missing
sum(miss_probe > 0.05)
#Number of probes with > 10% missing
sum(miss_probe > 0.1)
miss_probe_f <- cut(miss_probe, breaks = seq(0, 1, 0.05))
table(miss_probe_f)
data.frame(missing_interval = miss_probe_f) %>%
	filter(!is.na(missing_interval)) %>%
	ggplot(aes(missing_interval)) + 
	geom_bar() +
	theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
	labs(title = "Probe missing rate distribution")


#keep samples with missing < 10% and probes with missing < 5%
eset_Mvals <- eset_Mvals[miss_probe < 0.05 , miss_sample < 0.1]
dim(eset_Mvals)

```

## Distributions

Probes have been cleaned based on MASK status and missingness. 

Samples have been cleaned based on missingness. 

Check status of normalization with boxplots and kernel density plots.

### Boxplots

```{r cache = TRUE}

boxplot(exprs(eset_Mvals), las = 2, ylab = "M-values")

```

### Density plots

```{r cache = TRUE}

plotDensities(eset_Mvals, main = "M-values", legend = FALSE)

```

### Remove 3 sample outliers with low M-vals

Three samples showed low median M-values. Remove them, then re-examine boxplots and density plots.

```{r}
MvalMed <- apply(exprs(eset_Mvals), 2, function(x) median(x, na.rm = T))
sort(MvalMed)[1:5]
lowMedSamp <- names(sort(MvalMed)[1:3])

pdat <- pData(eset_Mvals)
keep <- !pdat$Sample_Name %in% lowMedSamp

eset_Mvals <- eset_Mvals[, keep]
dim(eset_Mvals)
```

```{r}

boxplot(exprs(eset_Mvals), las = 2, ylab = "M-values")

```

```{r}

plotDensities(eset_Mvals, main = "M-values", legend = FALSE)

```


## PCA

```{r }
plotMDS(eset_Mvals, gene.selection = "common", pch = 16, main = "Point labels")
plotMDS(eset_Mvals, gene.selection = "common", main = "Sample ID labels")

```

# Intra-assay CV of probes using duplicated samples


```{r cache = TRUE}

pdat <- pData(eset_Mvals)
dupIDs <- pdat %>%
	filter(!is.na(dupMrOSID)) %>%
	pull(dupMrOSID)
dupIDs

e <- exprs(eset_Mvals)
cbind(pdat$Sample_Name[match(dupIDs, pdat$Sample_Name)],
      pdat$dupMrOSID[match(dupIDs, pdat$dupMrOSID)]
      )

cbind(pdat$Sample_Name[match(dupIDs, pdat$Sample_Name)],
      pdat$Sample_Name[match(dupIDs, pdat$dupMrOSID)]
      )

pdat %>%
	filter(!is.na(dupMrOSID)) %>%
	select(dupMrOSID, Sample_Name)

cvFun <- function(e1, dupIDs, pdat){
  dup1 <- e1[match(dupIDs, pdat$Sample_Name)]
  dup2 <- e1[match(dupIDs, pdat$dupMrOSID)]
  matDup <- cbind(dup1, dup2)
  matDup <- matDup[complete.cases(matDup),]
  if(length(matDup) > 0){
              meanDup <- rowMeans(matDup)
              sdDup <- apply(matDup, 1, sd)
              cvDup <- 100*(sdDup/meanDup)
              return(abs(mean(cvDup)))
      } else {
	      return(NA)
      }
}
probeCV <- apply(e, 1, cvFun, dupIDs = dupIDs, pdat = pdat)
head(sort(probeCV, decreasing = TRUE))

data.frame(intraAssayCV = probeCV) %>%
	filter(intraAssayCV <= 100) %>%
	ggplot(aes(intraAssayCV)) + 
	geom_density(fill = "blue")

#Add probeCV to feature data
f_dat <- fData(eset_Mvals)
f_dat <- f_dat %>%
	mutate(CVprobe = probeCV)
fData(eset_Mvals) <- f_dat

write_rds(eset_Mvals, file = "../data/formatted/eset_Mvals_clean.rds")
```
The intra-assay CV is `r mean(probeCV, na.rm = TRUE)`

There are `r sum(probeCV > 500 & !is.na(probeCV))` probes with intra-assay CV > 500.

There are `r sum(probeCV > 100 & !is.na(probeCV))` probes with intra-assay CV > 100.

There are `r sum(probeCV > 50 & !is.na(probeCV))` probes with intra-assay CV > 50.

There are `r sum(probeCV > 15 & !is.na(probeCV))` probes with intra-assay CV > 15.


All sample and probe QC completed. Feature data includes probe CVs, so you can filter by that later if desired.


# Blood cell type analysis

Does CBC or Horvath predicted cell types associate with PCs?

Also, do Horvath predictions associate with CBC?

```{r cache = TRUE}

eset_Mvals <- read_rds("../data/formatted/eset_Mvals_clean.rds")
f_dat <- fData(eset_Mvals)
p_dat <- pData(eset_Mvals)
e <- exprs(eset_Mvals)
miss_probe <- apply(e, 1, function(x) sum(is.na(x)))
sum(miss_probe > 0)
sum(f_dat$CVprobe >= 100)
sum(f_dat$CVprobe >= 100 & miss_probe == 0)
sum(miss_probe == 0 & f_dat$CVprobe < 100)
eset_sub <- eset_Mvals[miss_probe == 0 & f_dat$CVprobe < 100, ] 
eset_pca <- prcomp(t(exprs(eset_sub)), center = TRUE, scale = TRUE)
summary(eset_pca)$importance[,1:10]
eset_PC <- eset_pca[["x"]]
eset_PC <- as.data.frame(eset_PC)
eset_PC$ID <- row.names(eset_PC)
eset_PC <- eset_PC %>%
	select(ID, PC1, PC2)

pheno <- read_csv("../data/pheno/INFLAME.CSV")
phenoV1 <- read_csv("../data/pheno/V1FEB14.CSV")
phenoV1 <- phenoV1 %>%
	select(ID, GIRACE, GIWHITE, GIAA, GIASIAN, GIHISPA)
with(phenoV1, table(GIRACE, GIWHITE))
with(phenoV1, table(GIRACE, GIAA))
with(phenoV1, table(GIRACE, GIASIAN))
with(phenoV1, table(GIRACE, GIHISPA))
pheno <- pheno %>%
	inner_join(phenoV1, by = "ID")
pheno <- pheno %>%
	inner_join(p_dat, by = c("ID" = "Sample_Name"))
with(pheno, table(GIRACE))
pheno %>%
	filter(GIRACE != 1) %>%
	select(ID, GIRACE)

horvath <- read_csv("../data/horvath/output/MethylData.output.csv")
table(horvath$predictedGender)

eset_PC <- eset_PC %>%
	inner_join(pheno, by = "ID")

summary(eset_PC$LABASO) #basophils 
table(cut(eset_PC$LABASO, breaks = 4))
summary(eset_PC$LAEOSI) #eosinophils 
table(cut(eset_PC$LAEOSI, breaks = 4))
summary(eset_PC$LALYMP) #lymphocytes 
table(cut(eset_PC$LALYMP, breaks = 4))
summary(eset_PC$LAMONO) #monocytes 
table(cut(eset_PC$LAMONO, breaks = 4))
summary(eset_PC$LANEUT) #neutrophils 
table(cut(eset_PC$LANEUT, breaks = 4))

eset_PC %>%
	ggplot(aes(PC1, PC2)) +
	geom_point(aes(color = cut(LABASO, breaks = 4)))

eset_PC %>%
	ggplot(aes(PC1, PC2)) +
	geom_point(aes(color = cut(LAEOSI, breaks = 4)))

eset_PC %>%
	ggplot(aes(PC1, PC2)) +
	geom_point(aes(color = cut(LALYMP, breaks = 4)))

eset_PC %>%
	ggplot(aes(PC1, PC2)) +
	geom_point(aes(color = cut(LAMONO, breaks = 4)))

eset_PC %>%
	ggplot(aes(PC1, PC2)) +
	geom_point(aes(color = cut(LANEUT, breaks = 4)))
```



# Association analysis

Merge inflammation variables to pdat. Use limma for association.

```{r cache = TRUE, results = "asis"}
eset_Mvals <- read_rds("../data/formatted/eset_Mvals_clean.rds")
f_dat <- fData(eset_Mvals)
sum(f_dat$CVprobe >= 100)
sum(f_dat$CVprobe < 100)
eset_Mvals <- eset_Mvals[f_dat$CVprobe < 100,]
core_vars <- c("ID", "SITE", "V3AGE1")
outcome_var <- c("CYCRPJH", "CYTNFR2JH", "CYIFNGJH", "CYIL1BJH", "CYIL6JH", "CYTNFJH")

p_dat1 <- pData(eset_Mvals)
pheno <- read_csv("../data/pheno/INFLAME.CSV")

for(i in outcome_var){
  myvars <- c(core_vars, i)

  pheno2 <- pheno %>%
	select(any_of(myvars)) %>%
	mutate(SITE = as.factor(SITE))
  pheno2$outcome <- log(pheno2[[i]] + 0.01)

  p_dat <- p_dat1 %>%
	left_join(pheno2, c("Sample_Name" = "ID")) %>%
	arrange(sampOrder)
  #map_int(p_dat, function(x) sum(is.na(x)))
  #Must remove missings from eset and pData
  mykeep <- !is.na(p_dat$SITE) & !is.na(p_dat$V3AGE1) & !is.na(p_dat$outcome)
  eset_Mvals_mod <- eset_Mvals[, mykeep]
  p_dat <- p_dat[mykeep, ]
  dim(eset_Mvals_mod)
  dim(p_dat)

  design <- model.matrix(~ outcome + V3AGE1 + SITE, data = p_dat)
  fit <- lmFit(eset_Mvals_mod, design)
  fit <- eBayes(fit)
  results <- decideTests(fit[,"outcome"])
  print(i)
  summary(results)

  annot_cols <- c("probeID", "CpG_chrm", "CpG_beg", "gene")
  topTable(fit, coef = "outcome", confint = TRUE, genelist = fit$genes[,annot_cols]) %>%
	kable

  resultAll <- topTable(fit, coef = "outcome", confint = TRUE, sort.by = "none", number = Inf)

  EnhancedVolcano(resultAll,
		lab = resultAll$probeID,
		x = "logFC",
		y = "P.Value")

  write_csv(resultAll, file = paste0("../results/limma_",i,".csv"))

}


outcome_var <- c("CYCRPJH", "CYTNFR2JH", "CYIFNGJH", "CYIL1BJH", "CYIL6JH", "CYTNFJH")
for(i in outcome_var){
  res1 <- read_csv(paste0("../results/limma_", i, ".csv"))
  top <- res1 %>%
	  filter(adj.P.Val <= 0.05)
  write_csv(top, file = paste0("../results/limma_", i, "_top.csv"))
}



```

# SVA

Surrogate variable analysis (SVA) can be used to estimate and adjust for latent factors associated with technical batch effects.

```{r cache = TRUE, results = "asis"}
eset_Mvals <- read_rds("../data/formatted/eset_Mvals_clean.rds")
f_dat <- fData(eset_Mvals)
e <- exprs(eset_Mvals)
miss_probe <- apply(e, 1, function(x) sum(is.na(x)))
sum(miss_probe > 0)
sum(f_dat$CVprobe >= 100)
sum(f_dat$CVprobe >= 100 & miss_probe == 0)
sum(miss_probe == 0 & f_dat$CVprobe < 100)
#SVA requires no missings in expression data
eset_Mvals <- eset_Mvals[miss_probe == 0 & f_dat$CVprobe < 100, ] 
core_vars <- c("ID", "SITE", "V3AGE1")
outcome_var <- c("CYCRPJH", "CYTNFR2JH", "CYIFNGJH", "CYIL1BJH", "CYIL6JH", "CYTNFJH")

p_dat1 <- pData(eset_Mvals)
pheno <- read_csv("../data/pheno/INFLAME.CSV")

myvars <- c(core_vars, outcome_var[1])

pheno2 <- pheno %>%
	select(any_of(myvars)) %>%
	mutate(SITE = as.factor(SITE))
pheno2$outcome <- log(pheno2$CYCRPJH + 0.01)

p_dat <- p_dat1 %>%
	left_join(pheno2, c("Sample_Name" = "ID")) %>%
	arrange(sampOrder)
map_int(p_dat, function(x) sum(is.na(x)))
#Must remove missings from eset and pData
mykeep <- !is.na(p_dat$SITE) & !is.na(p_dat$V3AGE1) & !is.na(p_dat$outcome)
eset_Mvals_mod <- eset_Mvals[, mykeep]
p_dat <- p_dat[mykeep, ]
dim(eset_Mvals_mod)
dim(p_dat)
e <- exprs(eset_Mvals_mod)

mod <- model.matrix(~ outcome + V3AGE1 + SITE, data = p_dat)
mod0 <- model.matrix(~ V3AGE1 + SITE, data = p_dat)
n.sv = num.sv(e, mod, method="leek")
svobj = sva(e, mod, mod0, n.sv=n.sv)

modSv = cbind(mod,svobj$sv)
mod0Sv = cbind(mod0,svobj$sv)
pValuesSv = f.pvalue(e,modSv,mod0Sv)
qValuesSv = p.adjust(pValuesSv,method="BH")

fit = lmFit(e, modSv)
#fit <- lmFit(eset_Mvals_mod, design)
fit <- eBayes(fit)
annot_cols <- c("probeID", "CpG_chrm", "CpG_beg", "gene")
topTable(fit, coef = "outcome", confint = TRUE)

%>% kable

  resultAll <- topTable(fit, coef = "outcome", confint = TRUE, sort.by = "none", number = Inf)

  EnhancedVolcano(resultAll,
		lab = resultAll$probeID,
		x = "logFC",
		y = "P.Value")

  write_csv(resultAll, file = paste0("../results/limma_",i,".csv"))

}





```

# Create files for Horvath website

Readin files without normalization or probe masking. Horvath site wants to use their own normalization, and asks that input files have no missings in betas. 

```{r eval = FALSE, cache = TRUE, message = FALSE, warning = FALSE}

manifest <- readRDS("../data/raw/Evans_Project_002/OpenDMAP_sesame_manifest.rds")

IDATprefixes <- searchIDATprefixes(dir.name = "../data/raw/Evans_Project_002/idat_Files")

betaHor <- do.call(cbind, lapply(IDATprefixes, 
			       function(pfx){
			         pfx %>%
				       readIDATpair(manifest = manifest) %>%
				       getBetas(quality.mask = FALSE, 
						nondetection.mask = FALSE
						)
			       } 
			       )
)

base::apply(betaHor, 2, function(x) sum(is.na(x))) %>%
	base::sort(decreasing = TRUE) %>%
	head
sum(is.na(betaHor))/length(betaHor)

dat_pData <- read_csv("../data/raw/Evans_Project_002/Evans_Project_002_Sample_Sheet.csv", skip = 8)
dat_pData <- dat_pData %>%
	mutate(Basename = paste(Sentrix_ID, Sentrix_Position, sep = "_"))

#sample IDs in sample sheet are in the same order as sample names in betas file
sum(colnames(betaHor) != dat_pData$Basename)
sum(colnames(betaHor) == dat_pData$Basename)
cbind(colnames(betaHor), dat_pData$Basename)

colnames(betaHor) <- dat_pData$Sample_Name

betaHor_probes <- str_split(string = rownames(betaHor), pattern = "_")
betaHor_probes <- map_chr(betaHor_probes, function(x) x[1])
length(betaHor_probes)
dim(betaHor)
#868,701 probes from Mvals data
sum(duplicated(betaHor_probes))
#There are 210 duplicate probes when deleting everything after "_"! For those dups, I'll simply include the original probe ID.
rownames(betaHor)[duplicated(betaHor_probes)]
betaHor_probes[duplicated(betaHor_probes)] <- rownames(betaHor)[duplicated(betaHor_probes)]

rownames(betaHor) <- betaHor_probes

#Mvals_annot <- data.frame(probeID = Mvals_probes, onChip = 1L, stringsAsFactors = FALSE)

#subset to the 150 samples that passed QC.
eset_Mvals <- read_rds("../data/formatted/eset_Mvals_clean.rds")
pdat <- pData(eset_Mvals)
keep <- colnames(betaHor) %in% pdat$Sample_Name
betaHor <- betaHor[,keep]

pheno <- read_csv("../data/pheno/INFLAME.CSV")
pheno <- pheno %>%
	select(ID, Age = V3AGE1)

#sample annotation in same order as samples in betaMat
betaSamp <- data.frame(ID = colnames(betaHor), betaOrder = seq_along(colnames(betaHor)), stringsAsFactors = F)

pheno2 <- betaSamp %>%
	left_join(pheno, by = "ID") %>%
	arrange(betaOrder) %>%
	mutate(Tissue = "Blood WB") %>%
	mutate(Female = 0L) %>%
	mutate(Age = ifelse(is.na(Age), as.integer(mean(Age, na.rm = T)), Age)) %>%
	select(ID, Age, Female, Tissue)

write.csv(pheno2, file = "../data/horvath/input/sampleAnnotation.csv", 
	  row.names = F, quote = F)

horvathProbe <- read.csv("../data/horvath/input/datMiniAnnotation3.csv", header=T, stringsAsFactors = F)#28587 probes
sum(!horvathProbe$Name %in% rownames(betaHor)) #Darn, 2415 probes not in my data

betasDF <- as.data.frame(betaHor)
betasDF$ProbeID <- row.names(betaHor)
betasDF <- betasDF[,c(ncol(betasDF), 1:ncol(betasDF)-1)]
match1 <- match(horvathProbe[,1], betasDF[,1])
betasDFreduced <- betasDF[match1,]
betasDFreduced[is.na(match1), 1] <- as.character(horvathProbe[is.na(match1), 1])

temp <- sapply(betasDFreduced, function(x) is.numeric(x))
sum(temp)
temp <- sapply(betasDFreduced, function(x) !is.numeric(x))
sum(temp)

write.csv(betasDFreduced, "../data/horvath/input/MethylData.csv", row.names = F, quote = F)

```
#Horvath cell type comparison

From [wikipedia](https://en.wikipedia.org/wiki/White_blood_cell), lymphocytes include B cells, NK cells, and T cells (CD4, CD8, gamma-delta, and regulatory).
Lymphocytes typically are 30% of white blood cells, and neutrophils are 60%. 

```{r cache = TRUE}

pheno <- read_csv("../data/pheno/INFLAME.CSV")
horvath <- read_csv("../data/horvath/output/MethylData.output.csv")
table(horvath$predictedGender)

summary(horvath$CD8T)
summary(horvath$CD4T)
summary(horvath$NK)
summary(horvath$Bcell)
summary(horvath$Mono)
summary(horvath$Gran)
horvath <- horvath %>%
	mutate(lymphocyte = CD8T + CD4T + NK + Bcell) %>%
	inner_join(pheno, by = c("SampleID" = "ID") ) %>%
	mutate(LALYMP = LALYMP/100,
	       LAMONO = LAMONO/100)

ggplot(horvath, aes(LALYMP, lymphocyte)) +
	geom_point()
cor.test(horvath$LALYMP, horvath$lymphocyte)
cor.test(horvath$LALYMP, horvath$lymphocyte, method = "spearman")

horvath %>%
	arrange(LALYMP) %>%
	select(LALYMP, lymphocyte) %>%
	as.data.frame

ggplot(horvath, aes(LAMONO, Mono)) +
	geom_point()
cor.test(horvath$LAMONO, horvath$Mono)
cor.test(horvath$LAMONO, horvath$Mono, method = "spearman")

horvath %>%
	arrange(LAMONO) %>%
	select(LAMONO, Mono) %>%
	as.data.frame
```


# R session

```{r}
sessionInfo()

```
