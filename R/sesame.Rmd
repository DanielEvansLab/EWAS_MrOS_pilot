---
title: "EWAS pilot in MrOS"
author: "Dan Evans"
output: 
  BiocStyle::html_document:
    toc_float: true
    toc_depth: 3
    fig_caption: yes

fontsize: 14 pt

vignette: >
  %\VignetteIndexEntry{EWAS pilot in MrOS}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}

---

# Introduction

More drugs to examine. Anti-NGF and might be associated with OA. Anti-sclerostin and heart disease. 

DNA methylation quantity is expressed as $\beta$ 

$$ \beta = M/(M + U)  $$

Where M = hybridization signal from a methylated version of a cytosine nucleotide and 
U =  hybridization signal from an unmethylated version of a cytosine nucleotide. 

A detection probability represents the probability of a detected signal being background flourescence. If the probability is high, the signal is more likely to be background, and the value should be set to missing.

Standard workflows suggest to remove data points with detection P-value > 0.05.  

# Processing Illumina EPIC array with Sesame package

## Sesame introduction

- EWAS array Illumina EPIC 850 + custom content

- LifeEGX worked with Sesame developer to process chips. LifeEGX recommends Sesame

- Sesame is a [bioconductor package](https://www.bioconductor.org/packages/release/bioc/html/sesame.html)
  + Improvements on previous EWAS packages for low-level processing. 
  + Existing methods do not identify artifacts associated with detection failure. Sources of failure include: insufficient DNA due to germline or somatic deletions or hyperpolymorphism, probe cross-hybridization. 
  + P-value with out-of-band array hybridization: pOOBAH
  + Reduces technical artifacts

```{r, setup}
knitr::opts_chunk$set(cache.lazy = FALSE)
```

## Sesame installation on UCR cluster

Installation of sesame and dependencies went fine, no errors or warnings.

Upgrade installed sesame version 1.6.

Can check version of loaded packages with sessionInfo()

```{r, eval = FALSE}
BiocManager::install("sesame", lib = "~/Rlibs")
BiocManager::install("sesameData", lib = "~/Rlibs")
```

## Load libraries
```{r message = FALSE}
library(tidyverse)
library(readxl)
library(knitr)
library(sesame)
library(wheatmap)
library(multtest)
library(limma)
library(RColorBrewer)
```

## Import and normalize data

Reading the data with openSesame takes about 55 minutes. 

```{r cache = TRUE, message = FALSE, warning = FALSE}

# manifest <- read.csv("../data/raw/Evans_Project_002/CombinedManifestEPICplus.manifest.LifeEGX.csv", header = T, stringsAsFactors = F, na.strings = c("NA", ""))

manifest <- readRDS("../data/raw/Evans_Project_002/OpenDMAP_sesame_manifest.rds")

IDATprefixes <- searchIDATprefixes(dir.name = "../data/raw/Evans_Project_002/idat_Files")

#specifying custom manifest works using rds manifest, not the csv manifest
t1 <- Sys.time()
betas <- openSesame(IDATprefixes, 'custom', manifest = manifest)
Sys.time() - t1
#Warnings issued. The sesame vignette also displayed these warnings, so I'm not concerned. 
#50: In readChar(con, nchars = n) : truncating string with embedded nuls

sum(is.na(betas))
sum(is.na(betas))/length(betas)
sum(betas <= 0 & !is.na(betas))
sum(betas >= 1 & !is.na(betas))

Mvals <- BetaValueToMValue(betas)

#create sample annotation file for eset
dat_pData <- read_csv("../data/raw/Evans_Project_002/Evans_Project_002_Sample_Sheet.csv", skip = 8)
dat_pData <- dat_pData %>%
	mutate(Basename = paste(Sentrix_ID, Sentrix_Position, sep = "_"))

#read in dup list
dupList <- read_excel("../data/raw/MrOS_duplicates.xlsx")
names(dupList)[1] <- "dupMrOSID"

#sample IDs in sample sheet are in the same order as sample names in betas file
sum(colnames(betas) != dat_pData$Basename)
sum(colnames(betas) == dat_pData$Basename)
cbind(colnames(betas), dat_pData$Basename)
#merge dups into sample sheet
dat_pData <- dat_pData %>%
	mutate(sampOrder = seq_along(Sample_Name)) %>%
	left_join(dupList, by = c("Sample_Name" = "dup_ID")) %>%
	arrange(sampOrder)

colnames(Mvals) <- dat_pData$Sample_Name
row.names(dat_pData) <- dat_pData$Sample_Name

# Feature annotation
# Create feature annotation file. Find which probes are in 450K annotation that are not in EPIC, then combine_rows. Ensure all probes in the data are included in the annotation, and in the same order, then can create eset. 
annot_450 <- read_tsv("~/bigdata/EWAStools/arrayAnnotation/HM450.hg19.manifest.tsv")
xreact_450 <- read_xlsx("~/bigdata/EWAStools/arrayAnnotation/48639-non-specific-probes-Illumina450k.xlsx", sheet = "nonspecific cg probes")
# Are all cross-reactive probes marked as masked in annot_450? If so, I don't need to readin the cross-reactive list in the future
sum(!is.na(xreact_450$TargetID))
length(xreact_450$TargetID) #29,233
sum(!is.na(annot_450$probeID))
length(annot_450$probeID) #485,577
sum(xreact_450$TargetID %in% annot_450$probeID) #29,233
#Yes, all cross-reactive probes are in the 450K annotation file. 
# All they all marked as MASKED?
table(annot_450$MASK_general[annot_450$probeID %in% xreact_450$TargetID])
table(annot_450$MASK_mapping[annot_450$probeID %in% xreact_450$TargetID])
table(list(mask_general =  annot_450$MASK_general[annot_450$probeID %in% xreact_450$TargetID],
      mask_mapping = annot_450$MASK_mapping[annot_450$probeID %in% xreact_450$TargetID]
      ),
      deparse.level = 2
      )
#There are 2097 cross-reactive probes that are not labeled by either of the MASK variables
#Conclusion, I need to exclude cross-reactive probes from 450K array probes
#Just set them to TRUE for MASK_general
annot_450$MASK_general[annot_450$probeID %in% xreact_450$TargetID] <- TRUE
table(annot_450$MASK_general[annot_450$probeID %in% xreact_450$TargetID])
#EPIC Annotation
# Set MASK_general to TRUE for cross-reactive probes in EPIC array
annot_EPIC <- read_tsv("~/bigdata/EWAStools/arrayAnnotation/EPIC.hg19.manifest.tsv")
length(annot_EPIC$probeID)
table(annot_EPIC$MASK_general[annot_EPIC$probeID %in% xreact_450$TargetID])
annot_EPIC$MASK_general[annot_EPIC$probeID %in% xreact_450$TargetID] <- TRUE
#Remove EPIC probes that are on 450K
sum(annot_450$probeID %in% annot_EPIC$probeID)
sum(!annot_450$probeID %in% annot_EPIC$probeID)
annot_450 <- annot_450[!annot_450$probeID %in% annot_EPIC$probeID,]

#Combine 450 and EPIC
dat_fData <- bind_rows("EPIC" = annot_EPIC, "HM450" = annot_450, .id = "array")
#898,983 rows 
#Subset dat_fData to probes in data, then make same order
Mvals_probes <- str_split(string = rownames(Mvals), pattern = "_")
Mvals_probes <- map_chr(Mvals_probes, function(x) x[1])
length(Mvals_probes)
dim(Mvals)
#868,701 probes from Mvals data
sum(duplicated(Mvals_probes))
#There are 210 duplicate probes when deleting everything after "_"! For those dups, I'll simply include the original probe ID.
rownames(Mvals)[duplicated(Mvals_probes)]
Mvals_probes[duplicated(Mvals_probes)] <- rownames(Mvals)[duplicated(Mvals_probes)]
Mvals_annot <- data.frame(probeID = Mvals_probes, onChip = 1L, stringsAsFactors = FALSE)
dat_fData <- Mvals_annot %>%
	left_join(dat_fData, by = "probeID")
#868,701 in merged result
sum(is.na(dat_fData$probeID)) #0 
sum(is.na(dat_fData$onChip)) #0
sum(is.na(dat_fData$array)) #210, same as duplicated probes
sum(is.na(dat_fData$MASK_general)) #210, same as duplicated probes
table(dat_fData$array)
#Match probe order
dat_fData <- dat_fData[match(Mvals_probes, dat_fData$probeID),]
sum(Mvals_probes != dat_fData$probeID)
row.names(dat_fData) <- dat_fData$probeID
rownames(Mvals) <- dat_fData$probeID

#Create eset
eset_Mvals <- ExpressionSet(assayData = Mvals,
			    phenoData = AnnotatedDataFrame(dat_pData),
			    featureData = AnnotatedDataFrame(dat_fData)
			    )

write_rds(eset_Mvals, path = "../data/formatted/eset_Mvals.rds")

```

## Additional QC


## Create files for Horvath website
```{r, eval = FALSE}
library(data.table)
pheno <- fread("../data/pheno/INFLAME.CSV")
pheno <- pheno[,.(ID, V3AGE1)]
setnames(pheno, "V3AGE1", "Age")
#sample annotation in same order as samples in betaMat
samp <- fread("../data/raw/Evans_Project_002/Evans_Project_002_Sample_Sheet.csv", skip = 8)
samp[, index := seq_along(Sample_Name)]
sum(colnames(betaMat)!= samp$Sample_Name)
sum(colnames(betaMat)== samp$Sample_Name)
samp <- merge(samp, pheno, by.x = "Sample_Name", by.y = "ID", all.x = TRUE)
samp[, Tissue := "Blood WB"]
samp[, Female := 0L]
samp <- samp[order(index)]
setnames(samp, "Sample_Name", "ID")
samp <- samp[,.(ID, Age, Female, Tissue)]
samp[is.na(Age), Age := as.integer(mean(samp$Age, na.rm = TRUE))]
fwrite(samp, file = "../data/horvath/input/sampleAnnotation.csv", eol = "\r\n", na= "NA")

horvathProbe <- read.csv("../data/horvath/input/datMiniAnnotation3.csv", header=T, stringsAsFactors = F)#28587 probes
sum(!horvathProbe$Name %in% rownames(betaMat)) #Darn, 2415 probes not in my data

betasDF <- as.data.frame(betaMat)
betasDF$ProbeID <- row.names(betaMat)
betasDF <- betasDF[,c(ncol(betasDF), 1:ncol(betasDF)-1)]
match1 <- match(horvathProbe[,1], betasDF[,1])
betasDFreduced <- betasDF[match1,]
betasDFreduced[is.na(match1), 1] <- as.character(horvathProbe[is.na(match1), 1])

temp <- sapply(betasDFreduced, function(x) is.numeric(x))
sum(temp)
temp <- sapply(betasDFreduced, function(x) !is.numeric(x))
sum(temp)

write.csv(betasDFreduced, "../data/horvath/input/MethylData.csv", row.names = F, quote = F, eol = "\r\n")

```


## Missing analysis 

By sample and probe
```{r, eval = FALSE}
miss_sample <- apply(betaMat, 2, function(x) sum(is.na(x))/length(x) )
miss_probe <- apply(betaMat, 1, function(x) sum(is.na(x))/length(x) )
length(miss_sample)
length(miss_probe)
sum(is.na(miss_sample))
sum(is.na(miss_probe))
sum(miss_sample >= 0.95) #0 samples have missing rate greater than 
#no samples that are essentially blanks.
sum(miss_probe >= 1) #3229 completely missing probes. 
sum(miss_probe >= 0.95) #6608 Remove these, then determine number of samples with missing rate>0.05.
blank_probes <- names(miss_probe[miss_probe >= 0.95])
#remove probes with >=0.95 missingness
betaMat <- betaMat[!rownames(betaMat) %in% blank_probes, ]

# Now I can remove probes with missing rate > 5% and samples > 10%
miss_sample <- apply(betaMat, 2, function(x) sum(is.na(x))/length(x) )
miss_probe <- apply(betaMat, 1, function(x) sum(is.na(x))/length(x) )
sum(miss_probe > 0.05) #73843 probes with missing rate greater than 5%
sum(miss_probe > 0.05)/length(miss_probe) #8% probes removed 
sum(miss_sample > 0.10) # 7 samples with > 10% missing 
miss_sample[miss_sample > 0.1]
sum(miss_sample > 0.10)/length(miss_sample) #4% samples removed

#remove samples with missing >10% and probes with missing > 5%
blank_probes <- names(miss_probe[miss_probe > 0.05])
betaMat <- betaMat[!rownames(betaMat) %in% blank_probes, ]
blank_samples <- names(miss_sample[miss_sample > 0.10])
betaMat <- betaMat[, !colnames(betaMat) %in% blank_samples ]
dim(betaMat) #788242 probes, 153 samples

betasDT <- as.data.table(betaMat)
betasDT[,ProbeID := row.names(betaMat)]
setcolorder(betasDT,c("ProbeID", names(betasDT)[1:ncol(betasDT)-1]))
fwrite(betasDT, file = "../data/clean/betas_miss.csv", na = "NA")
betaMatT <- t(betaMat)
betasDT <- as.data.table(betaMatT)
betasDT[,ID := row.names(betaMatT)]
setcolorder(betasDT,c(ncol(betasDT), 1:(ncol(betasDT)-1)))
fwrite(betasDT, file = "../data/clean/betas_miss_tr.csv", na = "NA")
```

## Read IDATs into SigSet list
```{r, eval = FALSE, cache = TRUE, results = "asis"}

IDATprefixes <- searchIDATprefixes(dir.name = "../data/raw/Evans_Project_002/idat_Files")
#IDATprefixes <- IDATprefixes[2:3]
ssets <- lapply(IDATprefixes, readIDATpair)
chipSex <- sapply(ssets, inferSex)
chipEth <- sapply(ssets, inferEthnicity)

qc10 <- do.call(rbind, lapply(ssets, function(x)
    as.data.frame(sesameQC(x))))
qc10$sample_name <- names(ssets)

qctab <- qc10[,c('mean_beta_cg','frac_meth_cg','frac_unmeth_cg','sex','age')]
tab <- xtable(qctab)
print(tab, type = "html")
```


## Mean intensity

The mean {M,U} intensity can be reached by mean_intensity. Similarly, the mean M+U intensity can be reached by mean_intensity_total. Low intensities are symptomatic of low input or poor hybridization.

```{r, eval = FALSE, results = "asis"}

library(wheatmap)
p1 <- ggplot(qc10) +
    geom_bar(aes(sample_name, mean_intensity), stat='identity') +
    xlab('Sample Name') + ylab('Mean Intensity') +
    ylim(0,18000) +
    theme(axis.text.x = element_text(angle=90, vjust=0.5, hjust=1))
p2 <- ggplot(qc10) +
    geom_bar(aes(sample_name, mean_intensity_total), stat='identity') +
    xlab('Sample Name') + ylab('Mean M+U Intensity') +
    ylim(0,18000) +
    theme(axis.text.x = element_text(angle=90, vjust=0.5, hjust=1))
WGG(p1) + WGG(p2, RightOf())

```


# R session

```{r}
sessionInfo()

```
